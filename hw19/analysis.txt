-- Решение
1) Прогноз по возможному росту базы и росту данных. Самыми нагруженными с точки зрения данных являются таблицы с заказами (purchase, purchase_item),
партиями товаров (product_item), и таблицы с клиентами их контактными данными (customer, credit_card, phone, email).
Расчитаем примерно требуемый объем дискового пространства под нашу базу данных за последующие 5 лет (требования по хранения архивных заказов - 5 лет).

a) Таблица 'purchase'. 'purchase' является партицируемой по годам (см файл schema.sql). Расчитаем объем требуемых дисков.
Предположим что наше приложение будет высоконгруженным и средняя нагрузка на запись будет 200 заказов (QPS = 200).
Дополнительно заложим коэфициент 5 под возможный рост нагрузки в связи с увеличением количества клиентов интернет магазина и дополнительные данные.
В итоге будем иметь следующую оценку для требуемого объема данных для этой таблицы в террабайтах за последующие 5 лет:
SET @QPS_PURCHASE = 200;
SET @COEFFICIENT = 5;
SET @TIME_PERIOD = 24 * 60 * 60 * 365 * 5;
SET @TB_CONVERSION = 1024 * 1024 * 1024 * 1024;

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.purchase)) * @QPS_PURCHASE * @COEFFICIENT * (@TIME_PERIOD) / @TB_CONVERSION) AS `Size (Тб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'purchase'; (11 Тб)
Что касается модели хранения и архивации, то поскольку таблица purchase является партицируемой по годам,
и данные старше одного года крайне одного года будут запрашиваться на чтение,
то мы можем создать аналогичную по структуре таблицу 'purchase_archive' и привязать ее к табличному пространству,
чьи данные хранятся на более медленном и дешевом hhd диске. По истечению года мы будем DETACH партиции от purchase и ATTACH к 'purchase_archive'.
(В postgresql ATTACH и DETACH есть из коробки, в случае с MySQL можно воспользоваться чем то вроде (https://dba.stackexchange.com/questions/114471/calculate-row-size-and-max-row-size-for-a-table)
Те итого мы имеем концепцию "горячего" ('purchase') и "холодного архива" ('purchase_archive').
Для "горячего архива" будем брать ssd диски, так как нужно быстрое чтение и запись.
Для "холодного архива" будем брать hhd.
По 'purchase'
ssd = 11 / 5 = 2,2 Тб (за 5 лет)
hdd = (11 / 5) * 4 = 8,8 Тб (за 5 лет)

б) Таблица 'purchase_item'. 'purchase_item' является партицируемой по годам (см файл schema.sql). Учитывая, что в секунду будет в среднем создаваться 5 заказов,
дополнительно предположим, что в каждом заказе будет около 5 позиций.
Дополнительно заложим коэфициент 5 под возможный рост нагрузки в связи с увеличением количества клиентов интернет магазина и дополнительные данные.
В итоге будем иметь следующую оценку для требуемого объема данных для этой таблицы в террабайтах за последующие 5 лет:
SET @QPS_PURCHASE_ITEM = 200 * 5;
SET @COEFFICIENT = 5;
SET @TIME_PERIOD = 24 * 60 * 60 * 365 * 5;
SET @TB_CONVERSION = 1024 * 1024 * 1024 * 1024;

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.purchase_item)) * @@QPS_PURCHASE_ITEM * @COEFFICIENT * (@TIME_PERIOD) / @TB_CONVERSION) AS `Size (Тб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'purchase_item'; (68 Тб).
Здесь также будем использовать концепцию "горячего архива" и "холодного архива" как и для таблицы 'purchase'.
В итоге по 'purchase_item' нам потребуются следующие объемы дисков:
ssd = 68 / 5 = 13,6 Тб (за 5 лет)
hdd = (68 / 5) * 4 = 54,4 Тб (за 5 лет)

в) Таблица 'product_item'. В настоящий момент в нашем интернет магазине порядка 100 поставщиков (таблица 'supplier')
и порядка 30000 различных товаров (таблица 'product'). В среднем, у каждого поставщика порядка 100000 партий различных товаров (таблица 'product_item'),
причем распроданные партии удаляются из таблицы 'product_item'. Предположим что за 5 лет число поставщиков увеличится на 50% и составит 150.
Коэфициент запаса возьмем равным 2.
В итоге будем иметь следующую оценку для требуемого объема данных для этой таблицы в террабайтах за последующие 5 лет:
SET @SUPPLIER_COUNT = 150;
SET @AVERAGE_PRODUCT_ITEM_COUNT = 100000;
SET @GB_CONVERSION = 1024 * 1024;
SET @COEFFICIENT = 2;

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.product_item)) * @SUPPLIER_COUNT * @COEFFICIENT * @AVERAGE_PRODUCT_ITEM_COUNT / @GB_CONVERSION) AS `Size (Мб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'product_item'; (2522 Мб)
К таблице 'product_item' будет осуществляться интенсивный доступ на модификацию и чтение, поэтому эту таблицу привяжем к табличному пространству,
чьи данные хранятся на быстром  ssd диске.
В итоге по 'product_item' нам потребуются следующие объемы дисков:
ssd = 2,46 гб

г) Таблицы 'customer', 'credit_card', 'phone', 'email'. В нашей системе порядка 5000000 клиентов, в течении 5 лет рост составит порядка 50%,
те итого получим порядка 7500000 клиентов. По средней оценки у каждого клиента порядка 2 кредитных карт, 2 телефонов и 2 email.
Т.е. в итоге получим по 15000000 записей в каждой из таблиц 'credit_card', 'phone', 'email'. Коэфициент запаса возьмем равным 2.
В итоге будем иметь следующую оценку для требуемого объема данных для этих таблиц в террабайтах за последующие 5 лет:
SET @CUSTOMER_COUNT = 7500000;
SET @MB_CONVERSION = 1024 * 1024;
SET @COEFFICIENT = 2;

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.customer)) * @CUSTOMER_COUNT * @COEFFICIENT / @MB_CONVERSION) AS `Size (Мб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'customer'; (666 мб)

SET @GB_CONVERSION = 1024 * 1024 * 1024;

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.credit_card)) * 2 * @CUSTOMER_COUNT * @COEFFICIENT / @GB_CONVERSION) AS `Size (Гб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'credit_card'; (102 Гб)

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.email)) * 2 * @CUSTOMER_COUNT * @COEFFICIENT / @GB_CONVERSION) AS `Size (Гб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'email'; (76 Гб)

SELECT
    TABLE_NAME AS `Table`,
    ROUND(((DATA_LENGTH + INDEX_LENGTH) / (SELECT COUNT(*) FROM otus.phone)) * 2 * @CUSTOMER_COUNT * @COEFFICIENT / @GB_CONVERSION) AS `Size (Гб)`
FROM
    information_schema.TABLES
WHERE
        TABLE_SCHEMA = "otus" AND TABLE_NAME = 'phone'; (98 Гб)

В итоге на 'customer', 'credit_card', 'phone', 'email' потребуются следующие объемы дисков:
ssd = 276,6 гб (берем ssd тк, нам нужен быстрый и частый доступ на чтение к этим таблицам)

ИТОГО: на один сервер БД (а мы будем использовать класстеризацию и репликацию) на потребуется:
ssd = 2,2 Тб + 13,6 Тб + (2,46 / 1024) + (276,6 / 1024) = 16.1 Тб
hdd = 8,8 Тб + 54,4 Тб = 63,2 Тб

2) Рост пользователей в системе. Всплески одновременных соединений. В нашей системе будут две основные роли для создания подключение к БД:
a) Роль 'customer' (клиент интернет магазина), которая будет иметь следующие доступы:
purchase, purchase_item, customer, credit_card, phone, email, product_item (r,w),
supplier, product, unit, manufacturer, product_category_ref, product_category (r)
б) Роль поставщик 'supplier', которая будет иметь следующие доступы:
supplier, product_item (r,w);
product, unit, manufacturer, product_category_ref, product_category, purchase_item (r)
в) Администратор справочников 'admin', которая будет иметь следующие доступы:
product, unit, manufacturer, product_category_ref, product_category (r,w)

Нагрузочное тестирование показало чтобы обеспечивать ~ 200 QPS по созданию заказов
необходимо 6 экземляров нашего backend приложения с размером пула коннектов переменного размера (5-20 соединений) на экземпляр приложения,
те итого нужно 30-120 соедений на запись (роль подключения при соединении 'customer').
Кроме того нагрузка может увеличиваться до ~ 300 QPS по созданию заказов в черные патницы и тд.
Для этой цели мы используем автоскейлинг нашего бэкэнд приложения до 9 экземпляров и нам дополнительно потребуется (15-60)
соедений под ролью 'customer'. Те итого нам потребуется (45-180 соедений) на создание заказов.

Для нужд 'supplier' (изменение партий товаров и добавление новых) вполне будет достаточно пула с 1-10 соединениями.
Для нужн администратора справочников будет достаточно 1-5 соедений.
Те итого для осуществления операции записи возьмем с запасом 230 соединений на сервер БД.
Нагрузку на чтение перенесем на реплики класстера.

3) Класстеризация. Поскольку наше приложение является высоконагруженным, нам нужна отказоустойчивость в части
базы данных, поддержка failower в случае падения нод с БД в класстере. Кроме того мы хотели бы перенести нагрузку на чтение на реплики. Для этой цели будем использовать
MySql InnoDB Cluster c mysql-router. Всего в класстере будет 3 ноды с MySql (одна primary - будет принимать нагрузку на запись,
2 secondary - будут принимать нагрузку на чтение)

4) Репликация. Мы будем использовать каскандную репликацию от 2 из 3 нод класстера, чтобы дополнительно
создать реплику для OLAP отчетов за большой период, и реплику для снятия бэкапов

5) Стратегии бэкапа. Backup планируется создавать 1 раз в день с каскадной реплики, и дополнительно делать инкрементальные backup в течении дня.

6) Возможные угрозы и методы защиты от них.
6.1) Ограничение привелегий пользователей. В соответствии с требуемыми операциями.
В нашей системе будут три роли, для различных целей ('customer', 'supplier', 'admin')
6.2) Введение истории изменений персональных данных пользователей
(см таблицу 'customer_history').
6.3) организации защиты по внедрению SQL-кода (SQL иньекции)
6.4) сохранение backup в зашифрованном виде
6.5) проведение Disaster recovery test на класстере, с отключение нод и сети между ними
6.6) Использование ssl для подключение к класстеру.
6.7) Подключение к нодам класстера и каскадным репликам только из локальной сети
6.8) Умные пароли, отсутсвие паролей по умолчанию или стандартных
6.9) Мониторинг оставшегося места на диске с помощью Grafana и Prometheus.
Удаление старых заказов из архива (путем отсоеденение и дропа соответствующих партиций.)  Требования по хранению заказа 5 лет
